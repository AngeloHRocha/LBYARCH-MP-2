## Execution Time and Analysis Performance

    | Matrix Size | Average Execution Time |
    |-------------|------------------------|
    |   10 x 10   |  0.000000107 seconds   |
    |  100 x 100  |  0.000008747 seconds   |
    | 1000 x 1000 |  0.000758517 seconds   |

**Analysis:** The results show that the assembly implementation is extremely fast for small matrices and scales efficiently for larger ones. By implementing the conversion function in x86-64 assembly, computation is highly optimized since scalar SIMD registers and floating-point instructions perform calculations directly in the CPU, eliminating the overhead of C loops and array accesses. This allows very fast processing even for large matrices, while C handles input/output and memory management, providing flexibility and ease of use.

## Correctness Check

The screenshot below shows the input (float grayscale values) and the corresponding output (uint8 integer values) generated by the assembly conversion function.

![Correctness Check](screenshot.png)
